{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Load modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, sys, cv2, pickle\nfrom PIL import Image,ImageOps\nimport matplotlib.pyplot as plt\nfrom progressbar import ProgressBar\nimport random, itertools\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing, model_selection, metrics, feature_selection\nfrom sklearn import neighbors, linear_model, svm, tree, ensemble\nfrom sklearn.model_selection import GridSearchCV, learning_curve, train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score, make_scorer, hamming_loss\n\nfrom keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras import regularizers\nimport keras.utils.np_utils as kutils\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow as tf\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)\n\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/Kannada-MNIST/train.csv\", sep=\",\")\ntest = pd.read_csv(\"../input/Kannada-MNIST/test.csv\", sep=\",\")\ndig_mnist = pd.read_csv(\"../input/Kannada-MNIST/Dig-MNIST.csv\", sep=\",\")\nsample_submission = pd.read_csv(\"../input/Kannada-MNIST/sample_submission.csv\", sep=\",\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Class to create array for model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Create_Array:\n    def __init__(self, data, random_sample, random_state):\n        self.random_sample = random_sample\n        self.random_state = random_state\n        if random_sample == 1: self.data = data\n        else:\n            train_X, test_X, train_y, test_y = \\\n            train_test_split(data, data.label, test_size=random_sample, random_state=random_state, stratify=data.label)\n            test_X['label'] = test_y\n            self.data = test_X.reset_index(drop=\"index\")\n    def split_data(self, test_size, to_category):\n        self.test_size = test_size\n        train_X, test_X, train_y, test_y = \\\n        train_test_split(self.data.drop(columns=\"label\"), self.data.label, test_size=test_size, random_state=self.random_state, stratify=self.data.label)\n        train_X = train_X.reset_index(drop='index')\n        self.train_X = self.change_format_X(train_X)\n        test_X = test_X.reset_index(drop='index')\n        self.test_X = self.change_format_X(test_X)\n        train_y = train_y.reset_index(drop='index')\n        self.train_y = self.change_format_y(train_y, to_category)\n        test_y = test_y.reset_index(drop='index')\n        self.test_y = self.change_format_y(test_y, to_category)\n    def get_pie_chart(self, figsize):\n        label_dict = dict()\n        label_count = self.data.label.value_counts()\n        for k in label_count.index:\n            label_dict[label_count.index[k]] = label_count[k]\n        \n        def func(pct, allvals):\n            absolute = int(pct/100.*np.sum(allvals))\n            return \"{:0.0f}\\n{:0.2f} %\".format(absolute, pct)\n        \n        data = list(label_dict.values())\n        \n        fig, ax = plt.subplots(figsize=figsize, subplot_kw=dict(aspect=\"equal\"))\n        wedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data),\n                                          textprops=dict(color=\"w\"))\n        ax.legend(wedges, label_dict.keys(),\n                  title=\"Labels\",\n                  loc=\"center left\",\n                  bbox_to_anchor=(1, 0, 0.5, 1))\n        return fig\n    def show_one_image(self, figsize):\n        plt.figure(figsize=figsize)\n        ind = random.sample(k=1, population=set(self.data.index))\n        img = self.data.loc[ind[0]][\"pixel0\":].values.reshape(28,28)\n        plt.imshow(img)\n        plt.title(\"label : {}\".format(self.data.loc[ind[0]][\"label\"]))\n        return plt\n    def show_multiple_images(self, seed, figsize, show_plot):\n        random.seed(seed)\n        num_dict = dict()\n        for num in range(10):\n            ind = random.sample(k=1, population=set(self.data.loc[self.data.label==num].index))\n            num_dict[self.data.label[ind[0]]] = self.data.loc[ind[0]][\"pixel0\":].values.reshape(28,28)\n        self.num_dict = num_dict\n        if show_plot:\n            fig = plt.figure(figsize=figsize)\n            for k,v in num_dict.items():\n                ax = fig.add_subplot(5, 5, 1 + k)\n                ax.imshow(num_dict[k])\n                ax.title.set_text(\"label : {}\".format(k))\n    def change_format_X(self, data):\n        #return data.values.reshape(data.shape[0], 28, 28, 1)\n        return data.values.reshape(data.shape[0], 28, 28).reshape(data.shape[0], 28, 28, 1)\n    def change_format_y(self, data, to_category):\n        self.to_category = to_category\n        #pbar = ProgressBar()\n        #data_copy = data.copy()\n        y = []\n        if to_category:\n            for k in data.index:\n                y.append([data.loc[k]])\n            y = to_categorical(y)\n        else:\n            for k in data.index:\n                y.append(data.loc[k])\n            y = np.array(y)\n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = Create_Array(train, 1, 123)\n_ = dat.get_pie_chart(figsize=(10,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = dat.show_one_image(figsize=(3,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.show_multiple_images(figsize=(15,18), seed=93, show_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the dataset\ndat.split_data(test_size=0.15, to_category=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"dimension of train : {}\".format(dat.train_X.shape))\nprint(\"dimension of test : {}\".format(dat.test_X.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create model of cnn"},{"metadata":{"trusted":true},"cell_type":"code","source":"# History plot\ndef history_plot(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(len(acc))\n    \n    plt.figure(figsize=(10,5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"accuracy\")\n    plt.legend()\n    plt.grid(True)\n    \n    #plt.figure()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    plt.grid(True)\n    \n    #plt.show()\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\ndef get_confusion_matrix(Y, y_pred, figsize=(7,7), dpi=90, normalize=False, cmap=plt.cm.Blues):\n        cnf_matrix = confusion_matrix(Y, y_pred)\n        acc = metrics.accuracy_score(Y, y_pred)\n        \n        if normalize:\n            cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n            print(\"Normalized confusion matrix\")\n        else:\n            print('Confusion matrix, without normalization')\n        \n        plt.figure(figsize=figsize, dpi=dpi)\n        plt.imshow(cnf_matrix, interpolation='nearest', cmap=cmap)\n        title = 'Confusion matrix\\nAccuracy : {} %'.format(np.round(100*acc,2))\n        plt.title(title)\n        plt.colorbar()\n        tick_marks = np.arange(10)\n        xtick = [t for t in range(10)]\n        plt.xticks(tick_marks, xtick, rotation=0)\n        plt.yticks(tick_marks, xtick)\n        \n        fmt = '.2f' if normalize else 'd'\n        thresh = cnf_matrix.max() / 2.\n        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n            plt.text(j, i, format(cnf_matrix[i, j], fmt),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n        \n        plt.tight_layout()\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.core import Flatten, Dense, Dropout, Activation\nfrom keras.layers.convolutional import ZeroPadding2D, Convolution2D, MaxPooling2D, Conv2D\nfrom keras.layers import BatchNormalization\n\nmodel = Sequential()\n#model.add(ZeroPadding2D((2,2)))\nmodel.add(Conv2D(64,kernel_size=5,activation='relu',input_shape=(28,28,1),padding=\"same\"))\nmodel.add(ZeroPadding2D((2,2)))\nmodel.add(Conv2D(64,kernel_size=5,activation='relu'))\nmodel.add(MaxPooling2D(strides=(2,2)))\n\nmodel.add(ZeroPadding2D((2,2)))\nmodel.add(Conv2D(256,kernel_size=5,activation='relu',init='he_normal'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256,kernel_size=3,activation='relu',init='he_normal'))\nmodel.add(MaxPooling2D(strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512,kernel_size=3,activation='relu',init='he_normal'))\nmodel.add(Dropout(0.2))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512,kernel_size=3,activation='relu',init='he_normal'))\nmodel.add(MaxPooling2D(strides=(2,2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024, activation='relu', init='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2048, activation='relu', init='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.25, # Randomly zoom image \n        shear_range=0.2, #move top of image along without moving the bottom or vice versa\n        width_shift_range=0.25,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.25,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,  # randomly flip images\n        data_format=\"channels_last\" #per theano convention, tensorflow is channels_first \n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### from keras.models import Sequential\n### from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization\n### # Creating a Sequential Model and adding the layers\n### model = Sequential()\n### \n### model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n### model.add(BatchNormalization())\n### model.add(Conv2D(32,kernel_size=3,activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Dropout(0.4))\n### \n### model.add(Conv2D(64,kernel_size=3,activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Conv2D(64,kernel_size=3,activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Conv2D(64,kernel_size=3,activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Conv2D(64,kernel_size=3,activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n### model.add(BatchNormalization())\n### model.add(Dropout(0.5))\n### \n### model.add(Flatten())\n### model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(l=0.0001)))\n### model.add(BatchNormalization())\n### model.add(Dropout(0.5))\n### model.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Reshaping the array to 4-dims so that it can work with the Keras API\nx_train = dat.train_X\nx_test = dat.test_X\ny_train = dat.train_y\ny_test = dat.test_y\ninput_shape = (1, 28, 28)\n# Making sure that the values are float so that we can get decimal points after division\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n# Normalizing the RGB codes by dividing it to the max RGB value.\nx_train /= 255\nx_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# print the model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# fit the cnn model\nfrom keras.callbacks import ReduceLROnPlateau\nimport keras.optimizers as opt\n\ndef fit_model(model, epoch, batch_size):\n    # set up the optimizer\n    adam = opt.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n    model.compile(optimizer=adam,\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    # reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.0000001, verbose=1)\n    \n    history = model.fit_generator(datagen.flow(x_train.reshape(x_train.shape[0],28,28).reshape(x_train.shape[0],28,28,1),y_train,batch_size=batch_size), validation_data=(x_test.reshape(x_test.shape[0],28,28).reshape(x_test.shape[0],28,28,1), y_test),\n                                  samples_per_epoch=np.floor(y_train.shape[0] / batch_size) * batch_size,\n                                  nb_epoch=epoch, verbose=1, callbacks=[reduce_lr],\n                                  steps_per_epoch=200)\n    \n    #history = model.fit(x_train.reshape(x_train.shape[0],28,28).reshape(x_train.shape[0],28,28,1), y_train,\n    #                    nb_epoch=epoch,\n    #                    batch_size=batch_size,\n    #                    validation_data=(x_test.reshape(x_test.shape[0],28,28).reshape(x_test.shape[0],28,28,1), y_test),\n    #                    verbose=1)\n    return model, history","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"model, history = fit_model(model=model, epoch=100, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#_ = history_plot(history).savefig(\"../history_plot.jpg\", dpi=500, figsize=(100,100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"evaluation in train : \")\neval_train = model.evaluate(x_train.reshape(x_train.shape[0],28,28).reshape(x_train.shape[0],28,28,1), y_train)\nprint(eval_train)\nprint(\"evaluation in test : \")\neval_test = model.evaluate(x_test.reshape(x_test.shape[0],28,28).reshape(x_test.shape[0],28,28,1), y_test)\nprint(eval_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from numpy import argmax\n# Confusion matrix in test\npredicted_test = model.predict_classes(x_test.reshape(x_test.shape[0],28,28).reshape(x_test.shape[0],28,28,1))\n_ = get_confusion_matrix(Y=y_test, y_pred=predicted_test, normalize=False, dpi=75, figsize=(7,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def show_multiple_images_predicted(num_dict, model, figsize):\n    label_predicted = dict()\n    for lab_ref,img in num_dict.items():\n        lab_pred = model.predict_classes(img.reshape(1, 28, 28).reshape(1, 28, 28, 1))[0]\n        label_predicted[lab_ref] = lab_pred\n    fig = plt.figure(figsize=figsize)\n    for l_ref,l_pred in label_predicted.items():\n        ax = fig.add_subplot(5, 5, 1 + l_ref)\n        ax.imshow(num_dict[l_ref])\n        ax.title.set_text(\"label : {}\\npredicted : {}\".format(l_ref,l_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dat.show_multiple_images(figsize=(15,18), seed=1265439, show_plot=False)\nshow_multiple_images_predicted(dat.num_dict, model, (15,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction on the test set"},{"metadata":{"trusted":false},"cell_type":"code","source":"### test_to_predict = test.drop(columns=['id'])\n### test_to_predict = test_to_predict.astype('float32')\n### test_to_predict /= 255\n### \n### label_predicted = \\\n### model.predict_classes(test_to_predict.values.reshape(test_to_predict.shape[0], 28, 28).reshape(test_to_predict.shape[0], 28, 28, 1))\n### \n### test_predicted = test.copy()\n### test_predicted['label'] = label_predicted\n### \n### submission = test_predicted[[\"id\", \"label\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_to_predict = test.loc[:,\"pixel0\":].values.reshape(test.shape[0], 1, 28, 28)\ntest_to_predict = test_to_predict.astype(float)\ntest_to_predict /= 255.0\n\nlabel_predicted = \\\nmodel.predict_classes(test_to_predict.reshape(test_to_predict.shape[0], 28, 28).reshape(test_to_predict.shape[0], 28, 28, 1))\n\ntest_predicted = test.copy()\ntest_predicted['label'] = label_predicted\n\nsubmission = test_predicted[[\"id\", \"label\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.groupby(['label'])['label'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def show_images_on_test(data, seed, figsize):\n    random.seed(seed)\n    ind = random.sample(k=10, population=set(data.id))\n    img = data.drop(columns=['id','label'])\n    label = data['label']\n    id_img = data['id']\n    fig = plt.figure(figsize=figsize)\n    for k in range(len(ind)):\n        ax = fig.add_subplot(5, 5, 1 + k)\n        img_k = img.loc[ind[k]].values.reshape(28,28)\n        ax.imshow(img_k)\n        ax.title.set_text(\"label : {}\\nid : {}\".format(label[ind[k]],id_img[ind[k]]))\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"_ = show_images_on_test(test_predicted, 20191105, (15,18))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}